{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Documentation of CheckThat! Subtask 4b: Neural Representation learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run these setup cells first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers\n",
    "def normalize(txt: str) -> str:\n",
    "    return \" \".join(str(txt).lower().split())\n",
    "\n",
    "def compute_metrics(q_emb, doc_emb, gt_ids, doc_ids):\n",
    "    sims = cosine_similarity(q_emb, doc_emb)\n",
    "    ranks = []\n",
    "    rr1 = []\n",
    "    rr5 = []\n",
    "    rr10 = []\n",
    "    for i, row in enumerate(sims):\n",
    "        # sorted descending\n",
    "        order = np.argsort(-row)\n",
    "        gt_idx = doc_ids.index(gt_ids[i])\n",
    "        rank = int(np.where(order == gt_idx)[0][0]) + 1\n",
    "        ranks.append(rank)\n",
    "        rr1.append(1.0/rank if rank <= 1 else 0.0)\n",
    "        rr5.append(1.0/rank if rank <= 5 else 0.0)\n",
    "        rr10.append(1.0/rank if rank <= 10 else 0.0)\n",
    "    ranks = np.array(ranks)\n",
    "    metrics = {\n",
    "        \"MRR@1\": float(np.mean(rr1)),\n",
    "        \"MRR@5\": float(np.mean(rr5)),\n",
    "        \"MRR@10\": float(np.mean(rr10)),\n",
    "        \"Recall@5\": float((ranks <= 5).mean()),\n",
    "        \"Recall@10\": float((ranks <= 10).mean()),\n",
    "        \"MedianRank\": float(np.median(ranks))\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base-setup trials\n",
    "\n",
    "These trials employ dual encoders using an in-batch negatives training regime. Reproduce the base-setup results here by switching out models from the sentence-transformers library:\n",
    "\n",
    "- sentence-transformers/all-MiniLM-L6-v2\n",
    "- sentence-transformers/multi-qa-mpnet-base-dot-v1\n",
    "- sentence-transformers/msmarco-bert-base-dot-v5\n",
    "- intfloat/e5-large-v2\n",
    "\n",
    "Additionally, you can reproduce the batch-size trials (e.g. using intfloat/e5-large-v2) and the experiment without fine-tuning.\n",
    "\n",
    "Places to make changes are clearly mark with \"###Change here\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below serves to reproduce the exact results presented in the paper. To reproduce results exactly, only change the following in the \"exp\" dictionary under CONFIG\n",
    "\n",
    "- encoder_model (pick possible options from the commented-out options in the cell and paste it after \"encoder-model\" in the exp variable)\n",
    "- batch_size (pick values like 8, 16, 32, 64, depending on computational resources and paste it after \"batch_size\" in the exp variable)\n",
    "- \"fine_tune\" = False (for infloat without fine-tuning - for all other experiments \"fine_tune\" = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- REPRODUCIBILITY ------------------------------------------------\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "### Models\n",
    "# \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "# \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "# \"sentence-transformers/msmarco-bert-base-dot-v5\"\n",
    "# \"intfloat/e5-large-v2\"\n",
    "###\n",
    "\n",
    "# ---------------- CONFIG --------------------------------------------------------\n",
    "exp = {\n",
    "    \"experiment_name\":   \"intfloat-e5-large-v2_bs64_lr7e-6\",\n",
    "    ### Change here\n",
    "    \"encoder_model\":     \"intfloat/e5-large-v2\", \n",
    "    ### ---\n",
    "    \"query_field\":       \"tweet_text\",\n",
    "    \"normalize\":         True,\n",
    "    ### Change here\n",
    "    \"fine_tune\":         True,\n",
    "    ### ---\n",
    "    \"epochs\":            2,\n",
    "    ### Change here\n",
    "    \"batch_size\":        64,\n",
    "    ### ---\n",
    "    \"lr\":                7e-6,\n",
    "    \"use_hard_negatives\": False,\n",
    "}\n",
    "\n",
    "RUN_ID   = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "SAVE_DIR = f\"../models/{exp['experiment_name']}_{RUN_ID}\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "DATA_DIR = \"../data\"\n",
    "OUT_CSV  = \"../experiment_results/clef_neural_rep_exp_results.csv\"\n",
    "PRED_DIR = \"../predictions\"\n",
    "DEVICE   = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ---------------- LOAD DATA ----------------------------------------------------\n",
    "df_coll  = pd.read_pickle(f\"{DATA_DIR}/subtask4b_collection_data.pkl\")\n",
    "df_train = pd.read_csv(f\"{DATA_DIR}/subtask4b_query_tweets_train.tsv\", sep=\"\\t\")\n",
    "df_dev   = pd.read_csv(f\"{DATA_DIR}/subtask4b_query_tweets_dev.tsv\",   sep=\"\\t\")\n",
    "df_test  = pd.read_csv(f\"{DATA_DIR}/subtask4b_query_tweets_test_gold.tsv\", sep=\"\\t\")\n",
    "\n",
    "# build document texts\n",
    "def build_doc(row):\n",
    "    txt = row.title + \" [SEP] \" + row.abstract\n",
    "    return normalize(txt) if exp[\"normalize\"] else txt\n",
    "\n",
    "doc_ids   = df_coll.cord_uid.tolist()\n",
    "doc_texts = df_coll.apply(build_doc, axis=1).tolist()\n",
    "\n",
    "# ---------------- MODEL -------------------------------------------------------\n",
    "model = SentenceTransformer(exp[\"encoder_model\"], device=DEVICE)\n",
    "\n",
    "# ---------------- TRAINING DATA ------------------------------------------------\n",
    "if exp[\"fine_tune\"]:\n",
    "    examples = []\n",
    "    for _, row in df_train.iterrows():\n",
    "        uid = row.cord_uid\n",
    "        if uid not in doc_ids:\n",
    "            continue\n",
    "        q = normalize(row[exp[\"query_field\"]]) if exp[\"normalize\"] else row[exp[\"query_field\"]]\n",
    "        pos = doc_texts[doc_ids.index(uid)]\n",
    "        examples.append(InputExample(texts=[q, pos]))\n",
    "\n",
    "    train_dl = DataLoader(examples, shuffle=True, batch_size=exp[\"batch_size\"],\n",
    "                          num_workers=4, pin_memory=True)\n",
    "    loss_fn = losses.MultipleNegativesRankingLoss(model)\n",
    "    warmup = int(len(train_dl) * exp[\"epochs\"] * 0.1)\n",
    "\n",
    "    model.fit(\n",
    "        train_objectives = [(train_dl, loss_fn)],\n",
    "        epochs = exp[\"epochs\"],\n",
    "        warmup_steps = warmup,\n",
    "        optimizer_params = {\"lr\": exp[\"lr\"]},\n",
    "        weight_decay = 0.02,\n",
    "        output_path = SAVE_DIR,\n",
    "        use_amp = True\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# ---------------- EMBEDDINGS --------------------------------------------------\n",
    "print(\"Encoding corpus …\")\n",
    "doc_emb = model.encode(doc_texts, batch_size=256,\n",
    "                       convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "def encode_queries(df):\n",
    "    qs = df[exp[\"query_field\"]].tolist()\n",
    "    if exp[\"normalize\"]:\n",
    "        qs = [normalize(q) for q in qs]\n",
    "    return model.encode(qs, batch_size=256,\n",
    "                        convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "print(\"Encoding queries …\")\n",
    "q_emb_tr = encode_queries(df_train)\n",
    "q_emb_de = encode_queries(df_dev)\n",
    "q_emb_te = encode_queries(df_test)\n",
    "\n",
    "# ---------------- METRICS -----------------------------------------------------\n",
    "print(\"Computing metrics …\")\n",
    "train_metrics = compute_metrics(\n",
    "    q_emb_tr, doc_emb,\n",
    "    df_train.cord_uid.tolist(),\n",
    "    doc_ids\n",
    ")\n",
    "dev_metrics   = compute_metrics(\n",
    "    q_emb_de, doc_emb,\n",
    "    df_dev.cord_uid.tolist(),\n",
    "    doc_ids\n",
    ")\n",
    "test_metrics = compute_metrics(\n",
    "     q_emb_te, doc_emb,\n",
    "     df_test.cord_uid.tolist(),\n",
    "      doc_ids\n",
    ")\n",
    "\n",
    "print(\"=== Train Metrics ===\")\n",
    "for k,v in train_metrics.items():\n",
    "    print(f\"{k:8s}: {v:.4f}\")\n",
    "print(\"=== Dev Metrics ===\")\n",
    "for k,v in dev_metrics.items():\n",
    "    print(f\"{k:8s}: {v:.4f}\")\n",
    "print(\"=== Test Metrics ===\")\n",
    "for k,v in test_metrics.items():\n",
    "    print(f\"{k:8s}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunked tokenization + additional collection columns\n",
    "\n",
    "Use the cell below to reproduce the document metadata experiments.\n",
    "\n",
    "The places to change are clearly marked with \"### Change here\"\". For \"use_fields\" in exp, put in any combination of the document fields as a python list: [\"title\", \"abstract\", \"authors\", \"journal\", \"source_x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b474bda7481e4681ac844d1aa3685cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='402' max='402' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [402/402 02:39, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding corpus with chunking …\n",
      "Encoding queries …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c1e5f8682145e38f1571a06264ce5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c34f01031146f995eb49c96a9ad4bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metrics …\n",
      "=== Train Metrics ===\n",
      "MRR@1   : 0.6622\n",
      "MRR@5   : 0.7366\n",
      "MRR@10  : 0.7430\n",
      "Recall@5: 0.8487\n",
      "Recall@10: 0.8947\n",
      "MedianRank: 1.0000\n",
      "=== Dev Metrics ===\n",
      "MRR@1   : 0.6443\n",
      "MRR@5   : 0.7040\n",
      "MRR@10  : 0.7112\n",
      "Recall@5: 0.7936\n",
      "Recall@10: 0.8457\n",
      "MedianRank: 1.0000\n",
      "Logged results to ../experiment_results/clef_neural_rep_exp_results_paper_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------------- REPRODUCIBILITY ------------------------------------------------\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "# ---------------- CONFIG --------------------------------------------------------\n",
    "exp = {\n",
    "    \"experiment_name\": \"intfloat-e5-large-v2_lr7e-6_chunked\",\n",
    "    \"encoder_model\": \"intfloat/e5-large-v2\",\n",
    "    \"query_field\": \"tweet_text\",\n",
    "    \"normalize\": True,\n",
    "    \"fine_tune\": True,\n",
    "    \"epochs\": 2,\n",
    "    \"batch_size\": 64,\n",
    "    \"lr\": 7e-6,\n",
    "    ### Change here\n",
    "    # specify which document columns to include in encoding\n",
    "    # e.g. [\"title\", \"abstract\", \"authors\", \"journal\", \"source_x\"]\n",
    "    \"use_fields\":        [\"title\", \"abstract\"] \n",
    "    ### ---\n",
    "}\n",
    "\n",
    "RUN_ID = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "SAVE_DIR = f\"../models/{exp['experiment_name']}_{RUN_ID}\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "DATA_DIR = \"../data\"\n",
    "OUT_CSV = \"../experiment_results/clef_neural_rep_exp_results_paper_metadata.csv\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ---------------- HELPERS -------------------------------------------------------\n",
    "def normalize(txt: str) -> str:\n",
    "    return \" \".join(str(txt).lower().split())\n",
    "\n",
    "# ---------------- LOAD DATA ----------------------------------------------------\n",
    "df_coll  = pd.read_pickle(f\"{DATA_DIR}/subtask4b_collection_data.pkl\")\n",
    "df_train = pd.read_csv(f\"{DATA_DIR}/subtask4b_query_tweets_train.tsv\", sep=\"\\t\")\n",
    "df_dev   = pd.read_csv(f\"{DATA_DIR}/subtask4b_query_tweets_dev.tsv\",   sep=\"\\t\")\n",
    "df_test = pd.read_csv(f\"{DATA_DIR}/subtask4b_query_tweets_test_gold.tsv\", sep=\"\\t\")\n",
    "\n",
    "# build document texts using chosen fields, with custom preprocessing per field\n",
    "\n",
    "def build_doc(row):\n",
    "    parts = []\n",
    "    for field in exp[\"use_fields\"]:\n",
    "        if field == \"title\":\n",
    "            parts.append(row.title)\n",
    "        elif field == \"abstract\":\n",
    "            parts.append(row.abstract)\n",
    "        elif field == \"authors\":  # split long author lists, keep top 5\n",
    "            auths = [a.strip() for a in str(row.authors).split(\";\")]\n",
    "            parts.append(\"Authors: \" + \", \".join(auths[:5]))\n",
    "        elif field == \"journal\":  \n",
    "            parts.append(\"Journal: \" + str(row.journal))\n",
    "        elif field == \"source_x\":  # normalize semicolon list\n",
    "            srcs = [s.strip() for s in str(row.source_x).split(\";\")]\n",
    "            parts.append(\"Source: \" + \", \".join(srcs))\n",
    "        else:\n",
    "            # fallback\n",
    "            parts.append(str(getattr(row, field, \"\")))\n",
    "    txt = \" [SEP] \".join(parts)\n",
    "    return normalize(txt) if exp[\"normalize\"] else txt\n",
    "\n",
    "# apply to all documents\n",
    "ndocs = len(df_coll)\n",
    "doc_ids   = df_coll.cord_uid.tolist()\n",
    "doc_texts = [build_doc(r) for _, r in df_coll.iterrows()]\n",
    "\n",
    "# ---------------- MODEL & TOKENIZER -------------------------------------------\n",
    "model     = SentenceTransformer(exp[\"encoder_model\"], device=DEVICE)\n",
    "tokenizer = AutoTokenizer.from_pretrained(exp[\"encoder_model\"])\n",
    "\n",
    "def chunk_text(text, max_length=510, stride=50):\n",
    "    enc = tokenizer(\n",
    "        text,\n",
    "        truncation=False,\n",
    "        max_length=max_length,\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True\n",
    "    )\n",
    "    return [tokenizer.decode(ids, skip_special_tokens=True)\n",
    "            for ids in enc[\"input_ids\"]]\n",
    "\n",
    "# ---------------- TRAINING DATA ------------------------------------------------\n",
    "if exp[\"fine_tune\"]:\n",
    "    examples = []\n",
    "    for _, row in df_train.iterrows():\n",
    "        uid = row.cord_uid\n",
    "        if uid not in doc_ids:\n",
    "            continue\n",
    "        q_text = normalize(row[exp[\"query_field\"]]) if exp[\"normalize\"] else row[exp[\"query_field\"]]\n",
    "        doc_text = doc_texts[doc_ids.index(uid)]\n",
    "        for chunk in chunk_text(doc_text):\n",
    "            examples.append(InputExample(texts=[q_text, chunk]))\n",
    "\n",
    "    train_dl = DataLoader(\n",
    "        examples,\n",
    "        shuffle=True,\n",
    "        batch_size=exp[\"batch_size\"],\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    loss_fn = losses.MultipleNegativesRankingLoss(model)\n",
    "    warmup = int(len(train_dl) * exp[\"epochs\"] * 0.1)\n",
    "\n",
    "    model.fit(\n",
    "        train_objectives=[(train_dl, loss_fn)],\n",
    "        epochs          = exp[\"epochs\"],\n",
    "        warmup_steps    = warmup,\n",
    "        optimizer_params={\"lr\": exp[\"lr\"]},\n",
    "        weight_decay    = 0.02,\n",
    "        output_path     = SAVE_DIR,\n",
    "        use_amp         = True\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# ---------------- EMBEDDINGS --------------------------------------------------\n",
    "print(\"Encoding corpus with chunking …\")\n",
    "all_doc_embs = []\n",
    "for txt in doc_texts:\n",
    "    chunks    = chunk_text(txt)\n",
    "    chunk_embs = model.encode(\n",
    "        chunks,\n",
    "        batch_size=exp[\"batch_size\"],\n",
    "        convert_to_numpy=True,\n",
    "        show_progress_bar=False\n",
    "    )\n",
    "    mean_emb = np.mean(chunk_embs, axis=0)\n",
    "    max_emb  = np.max(chunk_embs, axis=0)\n",
    "    all_doc_embs.append((mean_emb + max_emb) / 2.0)\n",
    "\n",
    "# stack into (n_docs × dim) array\n",
    "doc_emb = np.vstack(all_doc_embs)\n",
    "\n",
    "def encode_queries(df, batch_size=256):\n",
    "    qs = df[exp[\"query_field\"]].tolist()\n",
    "    if exp[\"normalize\"]:\n",
    "        qs = [normalize(q) for q in qs]\n",
    "    return model.encode(qs, batch_size=batch_size, convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "print(\"Encoding queries …\")\n",
    "q_emb_tr = encode_queries(df_train)\n",
    "q_emb_de = encode_queries(df_dev)\n",
    "q_emb_te = encode_queries(df_test)\n",
    "\n",
    "# ---------------- METRICS -----------------------------------------------------\n",
    "print(\"Computing metrics …\")\n",
    "train_metrics = compute_metrics(q_emb_tr, doc_emb, df_train.cord_uid.tolist(), doc_ids)\n",
    "dev_metrics   = compute_metrics(q_emb_de, doc_emb, df_dev.cord_uid.tolist(), doc_ids)\n",
    "test_metrics = compute_metrics(q_emb_te, doc_emb, df_test.cord_uid.tolist(), doc_ids)\n",
    "\n",
    "print(\"=== Train Metrics ===\")\n",
    "for k, v in train_metrics.items():\n",
    "    print(f\"{k:8s}: {v:.4f}\")\n",
    "print(\"=== Dev Metrics ===\")\n",
    "for k, v in dev_metrics.items():\n",
    "    print(f\"{k:8s}: {v:.4f}\")\n",
    "print(\"=== Test Metrics ===\")\n",
    "for k, v in test_metrics.items():\n",
    "    print(f\"{k:8s}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a single Hard Negative per query using MultipleNegativesRankingLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No changes needed - setup will exactly reproduce the hard negative trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- REPRODUCIBILITY ------------------------------------------------\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "# ---------------- CONFIG --------------------------------------------------------\n",
    "exp = {\n",
    "    \"experiment_name\": \"intfloat-e5-large-v2_lr7e-6_HN_MNRL\",\n",
    "    \"encoder_model\": \"intfloat/e5-large-v2\",\n",
    "    \"query_field\": \"tweet_text\",\n",
    "    \"normalize\": True,\n",
    "    \"fine_tune\": True,\n",
    "    \"epochs\":  2,\n",
    "    \"batch_size\": 64,\n",
    "    \"lr\": 7e-6,\n",
    "    \"use_hard_negatives\": True,\n",
    "}\n",
    "\n",
    "RUN_ID   = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "SAVE_DIR = f\"../models/{exp['experiment_name']}_{RUN_ID}\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "DATA_DIR = \"../data\"\n",
    "OUT_CSV  = \"../experiment_results/clef_neural_rep_exp_results.csv\"\n",
    "PRED_DIR = \"../predictions\"\n",
    "DEVICE   = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ---------------- LOAD DATA ----------------------------------------------------\n",
    "df_coll  = pd.read_pickle(f\"{DATA_DIR}/subtask4b_collection_data.pkl\")\n",
    "df_train = pd.read_csv(f\"{DATA_DIR}/subtask4b_query_tweets_train.tsv\", sep=\"\\t\")\n",
    "df_dev   = pd.read_csv(f\"{DATA_DIR}/subtask4b_query_tweets_dev.tsv\",   sep=\"\\t\")\n",
    "df_test = pd.read_csv(f\"{DATA_DIR}/subtask4b_query_tweets_test_gold.tsv\", sep=\"\\t\")\n",
    "\n",
    "# build document texts\n",
    "def build_doc(row):\n",
    "    txt = row.title + \" [SEP] \" + row.abstract\n",
    "    return normalize(txt) if exp[\"normalize\"] else txt\n",
    "\n",
    "doc_ids   = df_coll.cord_uid.tolist()\n",
    "doc_texts = df_coll.apply(build_doc, axis=1).tolist()\n",
    "\n",
    "# ---------------- MODEL -------------------------------------------------------\n",
    "model = SentenceTransformer(exp[\"encoder_model\"], device=DEVICE)\n",
    "\n",
    "# MEMORY SAVING TWEAKS \n",
    "try:\n",
    "    #  Turn on HF gradient checkpointing\n",
    "    xformer = model._first_module().auto_model\n",
    "    xformer.gradient_checkpointing_enable()\n",
    "\n",
    "    #  Turn off KV-cache \n",
    "    xformer.config.use_cache = False\n",
    "\n",
    "    print(\"Enabled HF gradient-checkpointing and disabled use_cache\")\n",
    "except Exception as e:\n",
    "    print(\"Could not enable gradient checkpointing:\", e)\n",
    "# ---------------- TRAINING DATA ------------------------------------------------\n",
    "if exp[\"fine_tune\"]:\n",
    "    # load the 1xBM25 negative per tweet\n",
    "    hard_negs = pickle.load(open(\"../cache/hard_negs_v4.pkl\", \"rb\"))\n",
    "\n",
    "    examples = []\n",
    "    for _, row in df_train.iterrows():\n",
    "        uid = row.cord_uid\n",
    "        if uid not in doc_ids:\n",
    "            continue\n",
    "\n",
    "        # normalize query & positive as before\n",
    "        q   = normalize(row[exp[\"query_field\"]]) if exp[\"normalize\"] else row[exp[\"query_field\"]]\n",
    "        pos = doc_texts[doc_ids.index(uid)]\n",
    "\n",
    "        # pull exactly one BM25 negative for this tweet\n",
    "        neg_uid = hard_negs.get(int(row.post_id), [None])[0]\n",
    "        if neg_uid in doc_ids:\n",
    "            neg = doc_texts[doc_ids.index(neg_uid)]\n",
    "            examples.append(InputExample(texts=[q, pos, neg]))\n",
    "        else:\n",
    "            # fallback to pair‐only if no hard negative found (does not happen)\n",
    "            examples.append(InputExample(texts=[q, pos]))\n",
    "\n",
    "    train_dl = DataLoader(examples, shuffle=True, batch_size=exp[\"batch_size\"],\n",
    "                          num_workers=4, pin_memory=True)\n",
    "    loss_fn = losses.MultipleNegativesRankingLoss(model)\n",
    "    warmup = int(len(train_dl) * exp[\"epochs\"] * 0.1)\n",
    "\n",
    "    model.fit(\n",
    "        train_objectives = [(train_dl, loss_fn)],\n",
    "        epochs = exp[\"epochs\"],\n",
    "        warmup_steps = warmup,\n",
    "        optimizer_params = {\"lr\": exp[\"lr\"]},\n",
    "        weight_decay = 0.02,\n",
    "        output_path = SAVE_DIR,\n",
    "        use_amp = True\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# ---------------- EMBEDDINGS --------------------------------------------------\n",
    "print(\"Encoding corpus …\")\n",
    "doc_emb = model.encode(doc_texts, batch_size=256,\n",
    "                       convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "def encode_queries(df):\n",
    "    qs = df[exp[\"query_field\"]].tolist()\n",
    "    if exp[\"normalize\"]:\n",
    "        qs = [normalize(q) for q in qs]\n",
    "    return model.encode(qs, batch_size=256,\n",
    "                        convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "print(\"Encoding queries …\")\n",
    "q_emb_tr = encode_queries(df_train)\n",
    "q_emb_de = encode_queries(df_dev)\n",
    "q_emb_te = encode_queries(df_test)\n",
    "\n",
    "# ---------------- METRICS -----------------------------------------------------\n",
    "print(\"Computing metrics …\")\n",
    "train_metrics = compute_metrics(\n",
    "    q_emb_tr, doc_emb,\n",
    "    df_train.cord_uid.tolist(),\n",
    "    doc_ids\n",
    ")\n",
    "dev_metrics   = compute_metrics(\n",
    "    q_emb_de, doc_emb,\n",
    "    df_dev.cord_uid.tolist(),\n",
    "    doc_ids\n",
    ")\n",
    "test_metrics = compute_metrics(\n",
    "    q_emb_te,\n",
    "    doc_emb,\n",
    "    df_test.cord_uid.tolist(),\n",
    "    doc_ids\n",
    ")\n",
    "\n",
    "\n",
    "print(\"=== Train Metrics ===\")\n",
    "for k,v in train_metrics.items():\n",
    "    print(f\"{k:8s}: {v:.4f}\")\n",
    "print(\"=== Dev Metrics ===\")\n",
    "for k,v in dev_metrics.items():\n",
    "    print(f\"{k:8s}: {v:.4f}\")\n",
    "print(\"=== Test Metrics ===\")\n",
    "for k,v in test_metrics.items():\n",
    "    print(f\"{k:8s}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine chunked tokenization, additional metadata fields and hard negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No changes needed - will exactly reproduce the trial using hard negatives as well as chunked tokenization with additional metadata fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- REPRODUCIBILITY ------------------------------------------------\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "# ---------------- CONFIG --------------------------------------------------------\n",
    "exp = {\n",
    "    \"experiment_name\":  \"intfloat-e5-large-v2_lr7e-6_HN_chunked_all_fields\",\n",
    "    \"encoder_model\": \"intfloat/e5-large-v2\",\n",
    "    \"query_field\": \"tweet_text\",\n",
    "    \"normalize\": True,\n",
    "    \"fine_tune\": True,\n",
    "    \"epochs\": 2,\n",
    "    \"batch_size\": 64,\n",
    "    \"lr\": 7e-6,\n",
    "    \"use_hard_negatives\": True,\n",
    "    \"use_fields\": [\"title\", \"abstract\", \"authors\", \"journal\", \"source_x\"],\n",
    "    \"chunk_max_length\": 510,\n",
    "    \"chunk_stride\": 50\n",
    "}\n",
    "\n",
    "RUN_ID = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "SAVE_DIR = f\"../models/{exp['experiment_name']}_{RUN_ID}\"\n",
    "DATA_DIR = \"../data\"\n",
    "CACHE_NEG = \"../cache/hard_negs_v4.pkl\"\n",
    "OUT_CSV = \"../experiment_results/clef_neural_rep_exp_results.csv\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(OUT_CSV), exist_ok=True)\n",
    "\n",
    "def build_doc(row):\n",
    "    parts = []\n",
    "    for field in exp[\"use_fields\"]:\n",
    "        if field == \"title\":\n",
    "            parts.append(row.title)\n",
    "        elif field == \"abstract\":\n",
    "            parts.append(row.abstract)\n",
    "        elif field == \"authors\":\n",
    "            auths = [a.strip() for a in str(row.authors).split(\";\")]\n",
    "            parts.append(\"Authors: \" + \", \".join(auths[:5]))\n",
    "        elif field == \"journal\":\n",
    "            parts.append(\"Journal: \" + str(row.journal))\n",
    "        elif field == \"source_x\":\n",
    "            srcs = [s.strip() for s in str(row.source_x).split(\";\")]\n",
    "            parts.append(\"Source: \" + \", \".join(srcs))\n",
    "        else:\n",
    "            parts.append(str(getattr(row, field, \"\")))\n",
    "    txt = \" [SEP] \".join(parts)\n",
    "    return normalize(txt) if exp[\"normalize\"] else txt\n",
    "\n",
    "# ---------------- LOAD & PREPARE DATA ------------------------------------------\n",
    "df_coll  = pd.read_pickle(f\"{DATA_DIR}/subtask4b_collection_data.pkl\")\n",
    "df_train = pd.read_csv(f\"{DATA_DIR}/subtask4b_query_tweets_train.tsv\", sep=\"\\t\")\n",
    "df_dev   = pd.read_csv(f\"{DATA_DIR}/subtask4b_query_tweets_dev.tsv\",   sep=\"\\t\")\n",
    "df_test = pd.read_csv(f\"{DATA_DIR}/subtask4b_query_tweets_test_gold.tsv\", sep=\"\\t\")\n",
    "\n",
    "doc_ids   = df_coll.cord_uid.tolist()\n",
    "doc_texts = [build_doc(r) for _, r in df_coll.iterrows()]\n",
    "\n",
    "# ---------------- TOKENIZER & CHUNKING -----------------------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(exp[\"encoder_model\"])\n",
    "def chunk_text(text):\n",
    "    enc = tokenizer(\n",
    "        text,\n",
    "        truncation=False,\n",
    "        max_length=exp[\"chunk_max_length\"],\n",
    "        stride=exp[\"chunk_stride\"],\n",
    "        return_overflowing_tokens=True\n",
    "    )\n",
    "    return [\n",
    "        tokenizer.decode(ids, skip_special_tokens=True)\n",
    "        for ids in enc[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "# ---------------- MODEL & MEMORY TWEAKS ----------------------------------------\n",
    "model = SentenceTransformer(exp[\"encoder_model\"], device=DEVICE)\n",
    "try:\n",
    "    tm = model._first_module().auto_model\n",
    "    tm.gradient_checkpointing_enable()\n",
    "    tm.config.use_cache = False\n",
    "    print(\"Enabled gradient checkpointing, disabled cache\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# ---------------- TRAINING DATA ------------------------------------------------\n",
    "if exp[\"fine_tune\"]:\n",
    "    hard_negs = pickle.load(open(CACHE_NEG, \"rb\")) if exp[\"use_hard_negatives\"] else {}\n",
    "    examples = []\n",
    "    for _, row in df_train.iterrows():\n",
    "        uid = row.cord_uid\n",
    "        if uid not in doc_ids:\n",
    "            continue\n",
    "\n",
    "        q_text   = normalize(row[exp[\"query_field\"]]) if exp[\"normalize\"] else row[exp[\"query_field\"]]\n",
    "        pos_text = doc_texts[doc_ids.index(uid)]\n",
    "        pos_chunks = chunk_text(pos_text)\n",
    "\n",
    "        neg_chunks = None\n",
    "        if exp[\"use_hard_negatives\"]:\n",
    "            neg_uid = hard_negs.get(int(row.post_id), [None])[0]\n",
    "            if neg_uid in doc_ids:\n",
    "                neg_text   = doc_texts[doc_ids.index(neg_uid)]\n",
    "                neg_chunks = chunk_text(neg_text)\n",
    "\n",
    "        for p in pos_chunks:\n",
    "            if neg_chunks:\n",
    "                for n in neg_chunks:\n",
    "                    examples.append(InputExample(texts=[q_text, p, n]))\n",
    "            else:\n",
    "                examples.append(InputExample(texts=[q_text, p]))\n",
    "\n",
    "    train_dl = DataLoader(\n",
    "        examples,\n",
    "        shuffle=True,\n",
    "        batch_size=exp[\"batch_size\"],\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    loss_fn = losses.MultipleNegativesRankingLoss(model)\n",
    "    warmup  = int(len(train_dl) * exp[\"epochs\"] * 0.1)\n",
    "\n",
    "    model.fit(\n",
    "        train_objectives=[(train_dl, loss_fn)],\n",
    "        epochs = exp[\"epochs\"],\n",
    "        warmup_steps = warmup,\n",
    "        optimizer_params={\"lr\": exp[\"lr\"]},\n",
    "        weight_decay = 0.02,\n",
    "        output_path = SAVE_DIR,\n",
    "        use_amp = True\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# ---------------- EMBEDDINGS & EVALUATION -------------------------------------\n",
    "print(\"Encoding corpus with chunking …\")\n",
    "all_doc_embs = []\n",
    "for txt in doc_texts:\n",
    "    ch = chunk_text(txt)\n",
    "    embs = model.encode(ch,\n",
    "                        batch_size=exp[\"batch_size\"],\n",
    "                        convert_to_numpy=True,\n",
    "                        show_progress_bar=False)\n",
    "    all_doc_embs.append((embs.mean(axis=0) + embs.max(axis=0)) / 2.0)\n",
    "doc_emb = np.vstack(all_doc_embs)\n",
    "\n",
    "def encode_queries(df):\n",
    "    qs = df[exp[\"query_field\"]].tolist()\n",
    "    if exp[\"normalize\"]:\n",
    "        qs = [normalize(q) for q in qs]\n",
    "    return model.encode(qs,\n",
    "                        batch_size=256,\n",
    "                        convert_to_numpy=True,\n",
    "                        show_progress_bar=True)\n",
    "\n",
    "print(\"Encoding queries …\")\n",
    "q_emb_tr = encode_queries(df_train)\n",
    "q_emb_de = encode_queries(df_dev)\n",
    "q_emb_te = encode_queries(df_test)\n",
    "\n",
    "print(\"Computing metrics …\")\n",
    "train_metrics = compute_metrics(q_emb_tr, doc_emb, df_train.cord_uid.tolist(), doc_ids)\n",
    "dev_metrics   = compute_metrics(q_emb_de, doc_emb, df_dev.cord_uid.tolist(), doc_ids)\n",
    "test_metrics = compute_metrics(q_emb_te, doc_emb, df_test.cord_uid.tolist(), doc_ids)\n",
    "\n",
    "print(\"=== Train Metrics ===\")\n",
    "for k, v in train_metrics.items():\n",
    "    print(f\"{k:8s}: {v:.4f}\")\n",
    "print(\"=== Dev Metrics ===\")\n",
    "for k, v in dev_metrics.items():\n",
    "    print(f\"{k:8s}: {v:.4f}\")\n",
    "print(\"=== Test Metrics ===\")\n",
    "for k, v in test_metrics.items():\n",
    "    print(f\"{k:8s}: {v:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
