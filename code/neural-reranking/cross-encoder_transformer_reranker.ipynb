{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c533023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import ast\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "from scipy.special import softmax\n",
    "import random\n",
    "from transformers import set_seed\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "from typing import Dict, Iterable\n",
    "import json, pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7f22164",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dba81cf",
   "metadata": {},
   "source": [
    "# Data Read in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "000b2be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "train_preds = pd.read_csv(\"../../predictions/Neural_Representation_Learning/E5_base_setup_train_TOP100.tsv\", sep=\"\\t\")\n",
    "dev_preds = pd.read_csv(\"../../predictions/Neural_Representation_Learning/E5_base_setup_dev_TOP100.tsv\", sep=\"\\t\")\n",
    "test_preds = pd.read_csv(\"../../predictions/Neural_Representation_Learning/E5_base_setup_test_TOP100.tsv\",sep=\"\\t\")\n",
    "\n",
    "\n",
    "#----------------------------------------------fixed ------------------------------------------------------------------\n",
    "#collection:\n",
    "PATH_COLLECTION_DATA =  '../../data/subtask4b_collection_data.pkl'\n",
    "df_collection = pd.read_pickle(PATH_COLLECTION_DATA)\n",
    "\n",
    "#tweets \n",
    "PATH_QUERY_TRAIN_DATA = '../../data/subtask4b_query_tweets_train.tsv' \n",
    "PATH_QUERY_DEV_DATA = '../../data/subtask4b_query_tweets_dev.tsv'\n",
    "PATH_QUERY_TEST_DATA =  '../../data/subtask4b_query_tweets_test_gold.tsv'\n",
    "\n",
    "df_query_train = pd.read_csv(PATH_QUERY_TRAIN_DATA, sep = '\\t')\n",
    "df_query_dev = pd.read_csv(PATH_QUERY_DEV_DATA, sep = '\\t')\n",
    "df_query_test = pd.read_csv(PATH_QUERY_TEST_DATA, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e605ecf",
   "metadata": {},
   "source": [
    "# Data limitation\n",
    "- as we always give out our top 100 predictions in the previous steps, we need to limit them to the top 5/10/20 in this step\n",
    "- this has proven to be more successfull than taking all 100 predictions into account "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a506fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_predictions(pred_str):\n",
    "    pred_list = ast.literal_eval(pred_str)  \n",
    "    return str(pred_list[:5]) #change amount of papers here \n",
    "\n",
    "train_preds[\"preds\"] = train_preds[\"preds\"].apply(truncate_predictions)\n",
    "dev_preds[\"preds\"] = dev_preds[\"preds\"].apply(truncate_predictions)\n",
    "test_preds[\"preds\"] = test_preds[\"preds\"].apply(truncate_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce458053",
   "metadata": {},
   "source": [
    "# Data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6628678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds[\"preds\"] = train_preds[\"preds\"].apply(ast.literal_eval)\n",
    "dev_preds[\"preds\"] = dev_preds[\"preds\"].apply(ast.literal_eval)\n",
    "test_preds[\"preds\"] = test_preds[\"preds\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b9c50c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a lookup for the document and matching cord_ids\n",
    "df_collection[\"document\"] = df_collection[[\"title\", \"abstract\"]].apply(\n",
    "    lambda x: f\"{x['title']} {x['abstract']}\", axis=1\n",
    ")\n",
    "\n",
    "document_lookup = df_collection.set_index(\"cord_uid\")[\"document\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0883ce2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>htlvpvz5</td>\n",
       "      <td>Oral Management in Rehabilitation Medicine: Or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>yec87cye</td>\n",
       "      <td>Dysphagia presentation and management followin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>jv3u1c0e</td>\n",
       "      <td>SARS‐CoV‐2 RNA in dental biofilms: Supragingiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>h7hj64q5</td>\n",
       "      <td>Quantitative Salivary Proteomic Differences in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>fkwgq5mr</td>\n",
       "      <td>COVID-19: patient characteristics in the first...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id  cord_uid                                           document\n",
       "0        0  htlvpvz5  Oral Management in Rehabilitation Medicine: Or...\n",
       "1        0  yec87cye  Dysphagia presentation and management followin...\n",
       "2        0  jv3u1c0e  SARS‐CoV‐2 RNA in dental biofilms: Supragingiv...\n",
       "3        0  h7hj64q5  Quantitative Salivary Proteomic Differences in...\n",
       "4        0  fkwgq5mr  COVID-19: patient characteristics in the first..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this creates the appropriate reranking dataframe for the train-set\n",
    "rerank_data = []\n",
    "\n",
    "for _, row in train_preds.iterrows():\n",
    "    post_id = row[\"post_id\"]\n",
    "    candidate_list = row[\"preds\"]\n",
    "\n",
    "    for cord_uid in candidate_list:\n",
    "        if cord_uid in document_lookup:   \n",
    "            rerank_data.append({\n",
    "                \"post_id\": post_id,\n",
    "                \"cord_uid\": cord_uid,\n",
    "                \"document\": document_lookup[cord_uid]\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Missing metadata for paper {cord_uid}\")\n",
    "\n",
    "rerank_df = pd.DataFrame(rerank_data)\n",
    "rerank_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "839ad696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>cord_uid_x</th>\n",
       "      <th>document</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid_y</th>\n",
       "      <th>input_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>htlvpvz5</td>\n",
       "      <td>Oral Management in Rehabilitation Medicine: Or...</td>\n",
       "      <td>Oral care in rehabilitation medicine: oral vul...</td>\n",
       "      <td>htlvpvz5</td>\n",
       "      <td>Oral care in rehabilitation medicine: oral vul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>yec87cye</td>\n",
       "      <td>Dysphagia presentation and management followin...</td>\n",
       "      <td>Oral care in rehabilitation medicine: oral vul...</td>\n",
       "      <td>htlvpvz5</td>\n",
       "      <td>Oral care in rehabilitation medicine: oral vul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>jv3u1c0e</td>\n",
       "      <td>SARS‐CoV‐2 RNA in dental biofilms: Supragingiv...</td>\n",
       "      <td>Oral care in rehabilitation medicine: oral vul...</td>\n",
       "      <td>htlvpvz5</td>\n",
       "      <td>Oral care in rehabilitation medicine: oral vul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>h7hj64q5</td>\n",
       "      <td>Quantitative Salivary Proteomic Differences in...</td>\n",
       "      <td>Oral care in rehabilitation medicine: oral vul...</td>\n",
       "      <td>htlvpvz5</td>\n",
       "      <td>Oral care in rehabilitation medicine: oral vul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>fkwgq5mr</td>\n",
       "      <td>COVID-19: patient characteristics in the first...</td>\n",
       "      <td>Oral care in rehabilitation medicine: oral vul...</td>\n",
       "      <td>htlvpvz5</td>\n",
       "      <td>Oral care in rehabilitation medicine: oral vul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64260</th>\n",
       "      <td>14252</td>\n",
       "      <td>nlsv8bin</td>\n",
       "      <td>Pre-activated antiviral innate immunity in the...</td>\n",
       "      <td>when \"the airway immune cells of children are ...</td>\n",
       "      <td>nlsv8bin</td>\n",
       "      <td>when \"the airway immune cells of children are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64261</th>\n",
       "      <td>14252</td>\n",
       "      <td>io6f6z3l</td>\n",
       "      <td>Nasal priming by a murine coronavirus provides...</td>\n",
       "      <td>when \"the airway immune cells of children are ...</td>\n",
       "      <td>nlsv8bin</td>\n",
       "      <td>when \"the airway immune cells of children are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64262</th>\n",
       "      <td>14252</td>\n",
       "      <td>eflyypev</td>\n",
       "      <td>Reduced development of COVID-19 in children re...</td>\n",
       "      <td>when \"the airway immune cells of children are ...</td>\n",
       "      <td>nlsv8bin</td>\n",
       "      <td>when \"the airway immune cells of children are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64263</th>\n",
       "      <td>14252</td>\n",
       "      <td>spohl5ey</td>\n",
       "      <td>Single-dose intranasal vaccination elicits sys...</td>\n",
       "      <td>when \"the airway immune cells of children are ...</td>\n",
       "      <td>nlsv8bin</td>\n",
       "      <td>when \"the airway immune cells of children are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64264</th>\n",
       "      <td>14252</td>\n",
       "      <td>pmd78j61</td>\n",
       "      <td>Respiratory mucosal delivery of next-generatio...</td>\n",
       "      <td>when \"the airway immune cells of children are ...</td>\n",
       "      <td>nlsv8bin</td>\n",
       "      <td>when \"the airway immune cells of children are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64265 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_id cord_uid_x                                           document  \\\n",
       "0            0   htlvpvz5  Oral Management in Rehabilitation Medicine: Or...   \n",
       "1            0   yec87cye  Dysphagia presentation and management followin...   \n",
       "2            0   jv3u1c0e  SARS‐CoV‐2 RNA in dental biofilms: Supragingiv...   \n",
       "3            0   h7hj64q5  Quantitative Salivary Proteomic Differences in...   \n",
       "4            0   fkwgq5mr  COVID-19: patient characteristics in the first...   \n",
       "...        ...        ...                                                ...   \n",
       "64260    14252   nlsv8bin  Pre-activated antiviral innate immunity in the...   \n",
       "64261    14252   io6f6z3l  Nasal priming by a murine coronavirus provides...   \n",
       "64262    14252   eflyypev  Reduced development of COVID-19 in children re...   \n",
       "64263    14252   spohl5ey  Single-dose intranasal vaccination elicits sys...   \n",
       "64264    14252   pmd78j61  Respiratory mucosal delivery of next-generatio...   \n",
       "\n",
       "                                              tweet_text cord_uid_y  \\\n",
       "0      Oral care in rehabilitation medicine: oral vul...   htlvpvz5   \n",
       "1      Oral care in rehabilitation medicine: oral vul...   htlvpvz5   \n",
       "2      Oral care in rehabilitation medicine: oral vul...   htlvpvz5   \n",
       "3      Oral care in rehabilitation medicine: oral vul...   htlvpvz5   \n",
       "4      Oral care in rehabilitation medicine: oral vul...   htlvpvz5   \n",
       "...                                                  ...        ...   \n",
       "64260  when \"the airway immune cells of children are ...   nlsv8bin   \n",
       "64261  when \"the airway immune cells of children are ...   nlsv8bin   \n",
       "64262  when \"the airway immune cells of children are ...   nlsv8bin   \n",
       "64263  when \"the airway immune cells of children are ...   nlsv8bin   \n",
       "64264  when \"the airway immune cells of children are ...   nlsv8bin   \n",
       "\n",
       "                                              input_text  label  \n",
       "0      Oral care in rehabilitation medicine: oral vul...      1  \n",
       "1      Oral care in rehabilitation medicine: oral vul...      0  \n",
       "2      Oral care in rehabilitation medicine: oral vul...      0  \n",
       "3      Oral care in rehabilitation medicine: oral vul...      0  \n",
       "4      Oral care in rehabilitation medicine: oral vul...      0  \n",
       "...                                                  ...    ...  \n",
       "64260  when \"the airway immune cells of children are ...      1  \n",
       "64261  when \"the airway immune cells of children are ...      0  \n",
       "64262  when \"the airway immune cells of children are ...      0  \n",
       "64263  when \"the airway immune cells of children are ...      0  \n",
       "64264  when \"the airway immune cells of children are ...      0  \n",
       "\n",
       "[64265 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = rerank_df.merge(df_query_train, on=\"post_id\", how=\"left\")\n",
    "full_df[\"input_text\"] = full_df.apply(\n",
    "    lambda x: f\"{x['tweet_text']} [SEP] {x['document']}\", axis=1\n",
    ")\n",
    "\n",
    "full_df[\"label\"] = (full_df[\"cord_uid_x\"] == full_df[\"cord_uid_y\"]).astype(int)\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "136736e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with label 1: 10912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8489846728390259"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is a sanity check to see how many gold papers are in the predictions we are looking at \n",
    "num_label_1 = (full_df[\"label\"] == 1).sum()\n",
    "print(\"Number of rows with label 1:\", num_label_1)\n",
    "\n",
    "num_label_1 / len(df_query_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed6fdeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this just creates the reranking dataframe for the dev set  \n",
    "\n",
    "true_map     = df_query_dev.set_index(\"post_id\")[\"cord_uid\"].to_dict()\n",
    "tweet_map    = df_query_dev.set_index(\"post_id\")[\"tweet_text\"].to_dict()\n",
    "\n",
    "rerank_data_dev = []\n",
    "\n",
    "for _, row in dev_preds.iterrows():\n",
    "    pid = row[\"post_id\"]\n",
    "    candidates = row[\"preds\"]\n",
    "    true_uid = true_map[pid]\n",
    "    text = tweet_map[pid]\n",
    "\n",
    "    for cand in candidates:\n",
    "    \n",
    "        if cand not in document_lookup:\n",
    "            print(f\"⚠️ Missing metadata for {cand}\")\n",
    "            continue\n",
    "\n",
    "        rerank_data_dev.append({\n",
    "            \"post_id\": pid,\n",
    "            \"cord_uid_x\": cand,\n",
    "            \"tweet_text\": text,\n",
    "            \"document\": document_lookup[cand],\n",
    "            \"cord_uid_y\": true_uid,\n",
    "            \"label\": int(cand == true_uid)\n",
    "        })\n",
    "\n",
    "\n",
    "df_dev = pd.DataFrame(rerank_data_dev)\n",
    "\n",
    "df_dev[\"input_text\"] = df_dev.apply(\n",
    "    lambda x: f\"{x['tweet_text']} [SEP] {x['document']}\",\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d798413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = Dataset.from_pandas(full_df[[\"input_text\", \"label\"]])\n",
    "hf_dev = Dataset.from_pandas(df_dev[[\"input_text\", \"post_id\", \"cord_uid_x\", \"cord_uid_y\", \"label\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244bcd6a",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "- here we can select one of the three models to rerank\n",
    "- SciBERT, DistilBERT, and MedBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a023bf",
   "metadata": {},
   "source": [
    "## SciBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd473a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n",
    "\n",
    "def tokenize_fn(example):\n",
    "    return tokenizer(example[\"input_text\"], truncation=True,  max_length=512)\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"allenai/scibert_scivocab_uncased\",\n",
    "    num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e3124d",
   "metadata": {},
   "source": [
    "## DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "583bdd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#    \"distilbert-base-uncased\",\n",
    "#    num_labels=2\n",
    "#)\n",
    "#\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "#\n",
    "#def tokenize_fn(example):\n",
    "#    return tokenizer(example[\"input_text\"], truncation=True,  max_length=512)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b92ccd1",
   "metadata": {},
   "source": [
    "## MedBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd9a9f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASE_MODEL = \"Charangan/MedBERT\" \n",
    "#\n",
    "#tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#            BASE_MODEL,\n",
    "#            num_labels=2) \n",
    "#\n",
    "#def tokenize_fn(example):\n",
    "#    return tokenizer(example[\"input_text\"], truncation=True,  max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e8dac0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b891c86ee448d283fdff13bb199be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/64265 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc9cc7aeb7345f5b4d3396f3cca9a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = hf_dataset.map(tokenize_fn, batched=True)\n",
    "tokenized_dev = hf_dev.map(tokenize_fn, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3e703c",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65c76003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device count : 1\n",
      "Device name  : NVIDIA GeForce RTX 2060 SUPER\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device count :\", torch.cuda.device_count())\n",
    "print(\"Device name  :\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57fded15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we just create the data_collator with our tokenizer\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a135028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the trainer with according hyperparameters \n",
    "training_args = TrainingArguments(\n",
    "   output_dir=\"./scibert-reranker\",\n",
    "   save_strategy=\"epoch\",\n",
    "   learning_rate=2e-5,\n",
    "   per_device_train_batch_size=16,\n",
    "   num_train_epochs=3,\n",
    "   weight_decay=0.01,\n",
    "   logging_dir=\"./logs\",\n",
    "   logging_steps=100,\n",
    "   save_total_limit=1,\n",
    "   fp16=True,\n",
    "   seed = SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82f31148",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset, \n",
    "    eval_dataset = tokenized_dev,\n",
    "    data_collator=data_collator \n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3709b2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12051' max='12051' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12051/12051 1:25:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.450400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.339200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.309100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.282400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.315700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.284300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.261400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.279600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.284100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.278900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.273100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.275800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.265300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.268300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.246100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.271200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.239500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.275600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.295000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.277300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.276200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.247900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.265300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.242000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.226200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.240500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.238300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.257900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.233300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.244700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.236900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.245700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.249100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.251700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.234200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.219100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.232500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.220200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.241900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.248100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.201400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.195600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.195900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.196000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.202100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.206100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.192300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.190300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.191800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.195700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.209300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.185900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.185900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.198500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.180900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.201600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.188300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.174400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.204300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.198300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.188900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.191600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.165600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.182000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.205400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.164300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.174600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.202300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.198100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.175300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.201800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.177800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.202100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.183900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.208900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.170400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.169600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.196100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.188700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.157100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.144400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>0.125300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.148800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.127700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.136600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>0.121500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.143100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>0.158900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.114300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>0.169500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.135200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>0.135400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>0.117900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.110900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.134500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>0.129200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>0.138700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>0.117000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.141200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>0.159400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>0.147700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10300</td>\n",
       "      <td>0.136700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.144300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.153700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>0.118900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>0.123300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.140900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10900</td>\n",
       "      <td>0.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.139200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11100</td>\n",
       "      <td>0.159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>0.127800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11300</td>\n",
       "      <td>0.133300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>0.137600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.136500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>0.123100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11700</td>\n",
       "      <td>0.162400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>0.143800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11900</td>\n",
       "      <td>0.141100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.152600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12051, training_loss=0.19806835932530226, metrics={'train_runtime': 5130.0186, 'train_samples_per_second': 37.582, 'train_steps_per_second': 2.349, 'total_flos': 5.070144281232864e+16, 'train_loss': 0.19806835932530226, 'epoch': 3.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242db8a6",
   "metadata": {},
   "source": [
    "# Load in Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e595f8",
   "metadata": {},
   "source": [
    "- this lets us run inference and test metrics without having to train all over again\n",
    "- just load in a pretrained model by providing the models path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fce9173",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"scibert-reranker/checkpoint-12051\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH) #here we can load in the pretrained models \n",
    "\n",
    "model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "trainer.model = model\n",
    "\n",
    "SEP = tokenizer.sep_token or \"[SEP]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1758b97",
   "metadata": {},
   "source": [
    "# Get Metrics\n",
    "- this cell computes the relevant metrics by:\n",
    "    - mapping the true ranks of all datasets from the original data back to the according dataframes\n",
    "    - computing the metrics {MRR@1, MRR@5, MRR@10, Recall@1, Recall@5, Recall@10}\n",
    "    - building dataframes on which the model can make predictions\n",
    "    - predicting on all three splits: train, dev and test set\n",
    "    - printing out the metrics for all splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72f096e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b052b834874d52b2055798ff5b9e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/64265 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c45357e950e414695b706527cecef84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8160b4bb84584fc8b1d97bfa9dc420a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7230 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dev': {'MRR@1': 0.6735714285714286,\n",
      "         'MRR@10': 0.7205476190476189,\n",
      "         'MRR@5': 0.7205476190476189,\n",
      "         'Recall@1': 0.6735714285714286,\n",
      "         'Recall@10': 0.7921428571428571,\n",
      "         'Recall@5': 0.7921428571428571},\n",
      " 'test': {'MRR@1': 0.6092669432918395,\n",
      "          'MRR@10': 0.6594974642692486,\n",
      "          'MRR@5': 0.6594974642692486,\n",
      "          'Recall@1': 0.6092669432918395,\n",
      "          'Recall@10': 0.7316735822959889,\n",
      "          'Recall@5': 0.7316735822959889},\n",
      " 'train': {'MRR@1': 0.8176301252625846,\n",
      "           'MRR@10': 0.8317565289556264,\n",
      "           'MRR@5': 0.8317565289556264,\n",
      "           'Recall@1': 0.8176301252625846,\n",
      "           'Recall@10': 0.8489846728390259,\n",
      "           'Recall@5': 0.8489846728390259}}\n"
     ]
    }
   ],
   "source": [
    "def _true_ranks(df: pd.DataFrame) -> np.ndarray:\n",
    " \n",
    "    ranks = []\n",
    "    for _, g in df.groupby(\"post_id\"):\n",
    "        g_sorted = g.sort_values(\"score\", ascending=False)\n",
    "        true_uid = g[\"cord_uid_y\"].iloc[0]\n",
    "\n",
    "        match = np.where(g_sorted[\"cord_uid_x\"].values == true_uid)[0]\n",
    "        rank  = match[0] + 1 if match.size else np.inf\n",
    "        ranks.append(rank)\n",
    "\n",
    "    return np.asarray(ranks, dtype=float)\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(df: pd.DataFrame,\n",
    "                    cutoffs: Iterable[int] = (1, 5, 10)) -> Dict[str, float]:\n",
    "    ranks = _true_ranks(df)\n",
    "    rr    = 1.0 / ranks                                   \n",
    "    out = {}\n",
    "    for k in cutoffs:\n",
    "        mask = ranks <= k\n",
    "        out[f\"MRR@{k}\"]    = float((rr * mask).mean())\n",
    "        out[f\"Recall@{k}\"] = float(mask.mean())\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_rerank_dataframe(pred_df: pd.DataFrame,\n",
    "                           df_query: pd.DataFrame,\n",
    "                           document_lookup: Dict[str, str]) -> pd.DataFrame:\n",
    "    true_map  = df_query.set_index(\"post_id\")[\"cord_uid\"].to_dict()\n",
    "    tweet_map = df_query.set_index(\"post_id\")[\"tweet_text\"].to_dict()\n",
    "\n",
    "    rows = []\n",
    "    for _, row in pred_df.iterrows():\n",
    "        pid, candidates = row[\"post_id\"], row[\"preds\"]\n",
    "        true_uid, text  = true_map[pid], tweet_map[pid]\n",
    "\n",
    "        for cand in candidates:\n",
    "            rows.append({\n",
    "                \"post_id\"    : pid,\n",
    "                \"cord_uid_x\" : cand,\n",
    "                \"tweet_text\" : text,\n",
    "                \"document\"   : document_lookup[cand],\n",
    "                \"cord_uid_y\" : true_uid,\n",
    "                \"label\"      : int(cand == true_uid)\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "all_metrics = {}\n",
    "for split in [\"train\", \"dev\", \"test\"]:\n",
    "    pred_df  = globals()[f\"{split}_preds\"]          \n",
    "    df_query = globals()[f\"df_query_{split}\"]       \n",
    "\n",
    "   \n",
    "    df_tmp = build_rerank_dataframe(pred_df, df_query, document_lookup)\n",
    "\n",
    "\n",
    "    hf_ds = Dataset.from_pandas(\n",
    "        df_tmp[[\"tweet_text\", \"document\", \"post_id\",\n",
    "                \"cord_uid_x\", \"cord_uid_y\", \"label\"]].assign(\n",
    "            input_text=lambda x: x[\"tweet_text\"] + \" [SEP] \" + x[\"document\"]\n",
    "        )\n",
    "    )\n",
    "    tokenised = hf_ds.map(tokenize_fn, batched=True)\n",
    "    cols_to_remove = set(tokenised.column_names) - set(tokenizer.model_input_names)\n",
    "    if \"label\" in cols_to_remove:        \n",
    "        cols_to_remove.add(\"label\")\n",
    "    tokenised = tokenised.remove_columns(list(cols_to_remove))            \n",
    "    logits = trainer.predict(tokenised).predictions\n",
    "    df_tmp[\"score\"] = softmax(logits, axis=1)[:, 1]\n",
    "\n",
    "    globals()[f\"df_{split}\"] = df_tmp                \n",
    "    all_metrics[split]       = compute_metrics(df_tmp)\n",
    "\n",
    "\n",
    "pprint.pprint(all_metrics, width=120, compact=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
