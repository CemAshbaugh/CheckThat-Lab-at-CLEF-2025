{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edc0416c",
   "metadata": {},
   "source": [
    "AIRwaves at CheckThat! 2025: Scientific Claim Source Retrieval\n",
    "Implementation of a two‐stage IR pipeline for CLEF 2025 Task 4b:\n",
    "1) Sparse + dense candidate generation  \n",
    "2) Neural re‐ranking with MonoT5 and BERT variants  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7d04f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, ast, random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import T5ForConditionalGeneration, T5TokenizerFast\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# deterministic seeds\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "try:\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d43baea",
   "metadata": {},
   "source": [
    "# 1) Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d01b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_list_metrics(pred_lists, refs, ks=(1, 5)):\n",
    "    ranks = []\n",
    "    for pred, gold in zip(pred_lists, refs):\n",
    "        try:\n",
    "            r = next(i+1 for i,p in enumerate(pred) if p in gold)\n",
    "        except StopIteration:\n",
    "            r = len(pred)+1\n",
    "        ranks.append(r)\n",
    "    ranks = np.array(ranks)\n",
    "    res = {}\n",
    "    for k in ks:\n",
    "        rr = [1.0/r if r<=k else 0.0 for r in ranks]\n",
    "        res[f\"MRR@{k}\"]    = float(np.mean(rr))\n",
    "        res[f\"Recall@{k}\"] = float((ranks<=k).mean())\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e0cb72",
   "metadata": {},
   "source": [
    "## 2) Reranking Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4300ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MonoT5\n",
    "def score_pair(model, tok, query, doc, device):\n",
    "    with torch.no_grad():\n",
    "        inp = f\"Query: {query} Document: {doc} Relevant:\"\n",
    "        enc = tok(inp, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "        labs = tok(\"true\", return_tensors=\"pt\").input_ids.to(device)\n",
    "        out = model(**enc, labels=labs)\n",
    "        return -out.loss.item()\n",
    "\n",
    "def rerank_monot5(model, tok, query, cands, id2text, device, top_k=5, batch_size=16):\n",
    "    scores=[]\n",
    "    for i in range(0,len(cands),batch_size):\n",
    "        for pid in cands[i:i+batch_size]:\n",
    "            scores.append((pid, score_pair(model,tok,query,id2text[pid],device)))\n",
    "    scores.sort(key=lambda x:x[1], reverse=True)\n",
    "    return [p for p,_ in scores[:top_k]]\n",
    "\n",
    "# Bi‐encoder fallback\n",
    "def fallback_candidates(query, gold, bi, emb, ids, device, top_k=5):\n",
    "    qv = bi.encode(query, convert_to_tensor=True, normalize_embeddings=True).to(device)\n",
    "    sims = util.cos_sim(qv,emb)[0]\n",
    "    idxs = torch.topk(sims, k=top_k).indices.cpu().tolist()\n",
    "    c = [ids[i] for i in idxs]\n",
    "    if gold not in c: c.append(gold)\n",
    "    return c\n",
    "\n",
    "# MonoT5‐3B batched\n",
    "def rerank_batched(model, tok, query, cands, id2text, device, top_k=5, batch_size=16, alpha=0.7):\n",
    "    window = cands[:top_k]\n",
    "    inputs = [f\"Query: {query} Document: {id2text[p]} Relevant:\" for p in window]\n",
    "    raw=[]\n",
    "    for i in range(0,len(inputs),batch_size):\n",
    "        enc = tok(inputs[i:i+batch_size], return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(**enc).logits\n",
    "        tid = tok.convert_tokens_to_ids(\"true\")\n",
    "        raw.extend(torch.log_softmax(logits,-1)[:,0,tid].cpu().tolist())\n",
    "    arr=np.array(raw); mn, mx = arr.min(), arr.max()\n",
    "    norm=(arr-mn)/(mx-mn+1e-8)\n",
    "    base=np.linspace(1,0,len(window))\n",
    "    final=alpha*norm+(1-alpha)*base\n",
    "    paired=list(zip(window,final))\n",
    "    paired.sort(key=lambda x:x[1], reverse=True)\n",
    "    return [p for p,_ in paired[:top_k]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf571d7",
   "metadata": {},
   "source": [
    "## 3) Load Data & Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78af2324",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_path    = Path(\"/home/fs72760/nikitaz/data/subtask4b_collection_data.pkl\")\n",
    "train_q     = Path(\"/home/fs72760/nikitaz/data/subtask4b_query_tweets_train.tsv\")\n",
    "dev_q       = Path(\"/home/fs72760/nikitaz/data/subtask4b_query_tweets_dev.tsv\")\n",
    "test_q      = Path(\"/home/fs72760/nikitaz/data/subtask4b_query_tweets_test.tsv\")\n",
    "\n",
    "train_p     = Path(\"/home/fs72760/nikitaz/predictions/train_ranked_preds.tsv\")\n",
    "dev_p       = Path(\"/home/fs72760/nikitaz/predictions/dev_ranked_preds.tsv\")\n",
    "test_p      = Path(\"/home/fs72760/nikitaz/predictions/test_ranked_preds.tsv\")\n",
    "\n",
    "# load collection\n",
    "papers = pd.read_pickle(col_path)\n",
    "papers[\"text\"] = (papers[\"title\"].fillna(\"\")+\" \"+papers[\"abstract\"].fillna(\"\")).str.strip()\n",
    "id2text = dict(zip(papers.cord_uid, papers.text))\n",
    "paper_ids = papers.cord_uid.tolist()\n",
    "\n",
    "# load queries & preds\n",
    "train_df = pd.read_csv(train_q, sep=\"\\t\")\n",
    "dev_df   = pd.read_csv(dev_q,   sep=\"\\t\")\n",
    "test_df  = pd.read_csv(test_q,  sep=\"\\t\")\n",
    "pred_train = pd.read_csv(train_p, sep=\"\\t\", index_col=\"post_id\")\n",
    "pred_dev   = pd.read_csv(dev_p,   sep=\"\\t\", index_col=\"post_id\")\n",
    "pred_test  = pd.read_csv(test_p,  sep=\"\\t\", index_col=\"post_id\")\n",
    "pred_col   = \"preds\" if \"preds\" in pred_dev.columns else pred_dev.columns[0]\n",
    "\n",
    "# embed corpus with bi-encoder\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "bi = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device=device)\n",
    "def encode_corpus(texts, model, bs=64):\n",
    "    vecs=[]\n",
    "    for i in tqdm(range(0,len(texts),bs), desc=\"Encode corpus\"):\n",
    "        vecs.append(model.encode(texts[i:i+bs], convert_to_tensor=True, normalize_embeddings=True))\n",
    "    return torch.cat(vecs).to(device)\n",
    "paper_emb = encode_corpus(papers.text.tolist(), bi)\n",
    "\n",
    "# load rerankers\n",
    "tok = T5TokenizerFast.from_pretrained(\"t5-base\")\n",
    "m1  = T5ForConditionalGeneration.from_pretrained(\"castorini/monot5-base-msmarco-10k\").to(device).eval()\n",
    "m2  = T5ForConditionalGeneration.from_pretrained(\"castorini/monot5-3b-msmarco\").to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c72090c",
   "metadata": {},
   "source": [
    "## 4) Evaluate on Train / Dev / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b9283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df, preds in [(\"Train\", train_df, pred_train),\n",
    "                        (\"Dev\",   dev_df,   pred_dev),\n",
    "                        (\"Test\",  test_df,  pred_test)]:\n",
    "    refs = [[r] for r in df.cord_uid]\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    # MonoT5-base\n",
    "    p1=[]\n",
    "    for _,row in tqdm(df.iterrows(), total=len(df), desc=\"MonoT5-base\"):\n",
    "        qid, q = row.post_id, row.tweet_text\n",
    "        cands = ast.literal_eval(preds.at[qid,pred_col])\n",
    "        p1.append(rerank_monot5(m1, tok, q, cands, id2text, device))\n",
    "    print(\"Base:\", compute_list_metrics(p1, refs))\n",
    "    # MonoT5-3B\n",
    "    p2=[]\n",
    "    for _,row in tqdm(df.iterrows(), total=len(df), desc=\"MonoT5-3B\"):\n",
    "        qid, q, gold = row.post_id, row.tweet_text, row.cord_uid\n",
    "        cands = ast.literal_eval(preds.at[qid,pred_col])\n",
    "        if gold not in cands:\n",
    "            cands = fallback_candidates(q, gold, bi, paper_emb, paper_ids, device)\n",
    "        p2.append(rerank_batched(m2, tok, q, cands, id2text, device))\n",
    "    print(\"Batched:\", compute_list_metrics(p2, refs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
